import pandas as pd

# Load the data
file_path = '/mnt/data/red_wine.csv'
red_wine_df = pd.read_csv(file_path)

# Display the first few rows of the dataframe
red_wine_df.head()



summary_stats = red_wine_df.describe(include='all')

# Check for missing values
missing_values = red_wine_df.isnull().sum()

summary_stats, missing_values

from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score
from sklearn.preprocessing import LabelEncoder

# Extract features and target
X = red_wine_df.drop('type', axis=1)
y = red_wine_df['type']

# Encode the target variable
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Define models
models = {
    'Baseline': DummyClassifier(strategy='most_frequent'),
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Naive Bayes': GaussianNB(),
    'Decision Tree': DecisionTreeClassifier(),
    'SVM-Linear': SVC(kernel='linear', probability=True),
    'SVM-RBF': SVC(kernel='rbf', probability=True),
    'Random Forest': RandomForestClassifier()
}

# Define 10-fold cross-validation
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)

# Initialize dictionaries to store results
auc_scores = {}
accuracy_scores = {}

# Evaluate models
for name, model in models.items():
    # AUC
    auc = cross_val_score(model, X, y_encoded, cv=cv, scoring=make_scorer(roc_auc_score, needs_proba=True)).mean()
    auc_scores[name] = auc

    # Accuracy
    accuracy = cross_val_score(model, X, y_encoded, cv=cv, scoring='accuracy').mean()
    accuracy_scores[name] = accuracy

auc_scores, accuracy_scores

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=0)

# Fit the Random Forest model
rf_model = RandomForestClassifier(random_state=0)
rf_model.fit(X_train, y_train)

# Predict probabilities
y_prob = rf_model.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) - Random Forest')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

X_white = white_wine_df.drop('type', axis=1)
y_white = label_encoder.transform(white_wine_df['type'])

# Predict probabilities using the Random Forest model trained on red wine data
y_prob_white = rf_model.predict_proba(X_white)[:, 1]

# Compute ROC curve and AUC for white wine data
fpr_white, tpr_white, _ = roc_curve(y_white, y_prob_white)
roc_auc_white = auc(fpr_white, tpr_white)

roc_auc_white

rf_model_new = RandomForestClassifier(random_state=0)
rf_model_new.fit(X, y_encoded)

# Predict probabilities on white wine data using the new model
y_prob_white_new = rf_model_new.predict_proba(X_white)[:, 1]

# Compute ROC curve and AUC for white wine data
fpr_white_new, tpr_white_new, _ = roc_curve(y_white, y_prob_white_new)
roc_auc_white_new = auc(fpr_white_new, tpr_white_new)

roc_auc_white_new
